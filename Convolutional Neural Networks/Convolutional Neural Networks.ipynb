{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "### References\n",
    "\n",
    "* http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n",
    "* https://pdfs.semanticscholar.org/450c/a19932fcef1ca6d0442cbf52fec38fb9d1e5.pdf\n",
    "* https://arxiv.org/pdf/1609.04112.pdf\n",
    "* https://arxiv.org/pdf/1502.01852.pdf\n",
    "* http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf\n",
    "* https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html\n",
    "* https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/\n",
    "* https://peterroelants.github.io/posts/cross-entropy-softmax/\n",
    "\n",
    "ToDo:\n",
    "\n",
    "* What do the different objects and parametrizations in Keras do?\n",
    "  * https://keras.io/layers/convolutional/\n",
    "  * https://keras.io/layers/pooling/\n",
    "  * https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Foundations\n",
    "\n",
    "## The Convolution Operation\n",
    "\n",
    "ToDo: \n",
    "\n",
    "* Jianxin Wun paper https://pdfs.semanticscholar.org/450c/a19932fcef1ca6d0442cbf52fec38fb9d1e5.pdf\n",
    "* Jay Kuo paper https://arxiv.org/pdf/1609.04112.pdf\n",
    "* Kaiming He paper https://arxiv.org/pdf/1502.01852.pdf\n",
    "\n",
    "$$ (f \\ast g) = \\int_{-\\infty}^{\\infty}f(\\tau)g(t-\\tau)d\\tau $$\n",
    "\n",
    "<img src='resources/cnn-components.png'>\n",
    "\n",
    "## Pooling\n",
    "\n",
    "ToDo:\n",
    "\n",
    "* Dominik Scherer paper http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf\n",
    "\n",
    "Induces *spatial invariance* on the feature map and reduces dimensionality, by keeping the detected features and dropping the image size.\n",
    "\n",
    "## Softmax Activation and Cross-Entropy Loss\n",
    "\n",
    "The **softmax function**, or **normalized exponential function**, is a generalization of the logistic function that *\"squashes\"* a $K$-dimensional vector $z$ of arbitrary real values to a $K$-dimensional vector $\\sigma(z)$ of real values, for $K\\geq2$ where each entry is in the interval $(0,1)$ and all the entries add up to $1$.\n",
    "\n",
    "$$ \\sigma_j(z) = \\frac{e^{z_j}}{\\sum_ke^{z_k}} $$\n",
    "\n",
    "Cross entropy:\n",
    "\n",
    "$$ H(p,q) = -\\sum_xp(x)\\log q(x) $$\n",
    "\n",
    "## The Convolutional Neural Network Process\n",
    "\n",
    "ToDo:\n",
    "\n",
    "* Adit Deshpande paper https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html\n",
    "\n",
    "---\n",
    "\n",
    "1. Transform the input image into a matrix of pixel intensities.\n",
    "2. Apply a set of filters or feature detectors with their respective activations (usually ReLU or Leaky ReLU).\n",
    "3. Apply a pooling operation to induce spatial invariance and reduce dimensionality.\n",
    "4. Repeat steps 2 and 3 to keep obtaining features.\n",
    "5. Flatten the pooled feature maps.\n",
    "6. Input the flattened feature map into a fully connected neural network to be used on regression or classification tasks.\n",
    "7. Backpropagate errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
